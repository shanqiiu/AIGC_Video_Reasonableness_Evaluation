# -*- coding: utf-8 -*-
"""
æ—¶åºåˆç†æ€§åˆ†æå™¨ä¸»ç±»
"""

from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional, Sequence

import numpy as np
import torch

from .config import TemporalReasoningConfig
from ..fusion.decision_engine import FusionDecisionEngine
from ..instance_tracking import TemporalCoherenceConfig, TemporalCoherencePipeline
from ..keypoint_analysis.keypoint_analyzer import KeypointAnalyzer
from ..motion_flow.flow_analyzer import MotionFlowAnalyzer


@dataclass
class StructureAnalysisOutput:
    score: float
    vanish_score: float
    emerge_score: float
    anomalies: List[Dict]
    metadata: Dict[str, object]


class TemporalReasoningAnalyzer:
    """
    æ—¶åºåˆç†æ€§åˆ†æå™¨
    """

    def __init__(self, config: TemporalReasoningConfig):
        """
        åˆå§‹åŒ–åˆ†æå™¨

        Args:
            config: é…ç½®å¯¹è±¡
        """
        self.config = config
        self.motion_analyzer: Optional[MotionFlowAnalyzer] = None
        self.structure_pipeline: Optional[TemporalCoherencePipeline] = None
        self.keypoint_analyzer: Optional[KeypointAnalyzer] = None
        self.fusion_engine: Optional[FusionDecisionEngine] = None
        self._initialized = False

    def initialize(self):
        """åˆå§‹åŒ–æ‰€æœ‰å­æ¨¡å—"""
        if self._initialized:
            print("åˆ†æå™¨å·²åˆå§‹åŒ?")
            return

        print("=" * 50)
        print("æ­£åœ¨åˆå§‹åŒ–æ—¶åºåˆç†æ€§åˆ†æå™¨...")
        print("=" * 50)

        try:
            # 1. å…‰æµåˆ†æå™?
            print("\n[1/4] åˆå§‹åŒ–å…‰æµåˆ†æå™¨...")
            self.motion_analyzer = MotionFlowAnalyzer(self.config.raft)
            self.motion_analyzer.initialize()

            # 2. ç»“æ„ä¸€è‡´æ€§åˆ†æç®¡çº?
            print("\n[2/4] åˆå§‹åŒ–å®ä¾‹è¿½è¸?/ç»“æ„åˆ†æç®¡çº¿...")
            coherence_config = self._build_temporal_coherence_config()
            self.structure_pipeline = TemporalCoherencePipeline(coherence_config)
            self.structure_pipeline.initialize()

            # 3. å…³é”®ç‚¹åˆ†æå™¨
            print("\n[3/4] åˆå§‹åŒ–å…³é”®ç‚¹åˆ†æå™?...")
            self.keypoint_analyzer = KeypointAnalyzer(self.config.keypoint)
            self.keypoint_analyzer.initialize()

            # 4. èåˆå†³ç­–å¼•æ“
            print("\n[4/4] åˆå§‹åŒ–èåˆå†³ç­–å¼•æ“?...")
            self.fusion_engine = FusionDecisionEngine(self.config.fusion, cotracker_validator=None)

            self._initialized = True
            print("\n" + "=" * 50)
            print("æ—¶åºåˆç†æ€§åˆ†æå™¨åˆå§‹åŒ–å®Œæˆï¼")
            print("=" * 50)

        except Exception as exc:
            print(f"\né”™è¯¯: åˆå§‹åŒ–å¤±è´?: {exc}")
            raise

    def _build_temporal_coherence_config(self) -> TemporalCoherenceConfig:
        """æ„é€ ç»“æ„åˆ†æç®¡çº¿çš„é…ç½®ã€?"""
        meta_info_path = Path(self.config.output_dir) / "temporal_coherence_meta.json"
        cotracker_checkpoint = (
            self.config.tracker.cotracker_checkpoint
            or self.config.tracker.model_path
            or ".cache/scaled_offline.pth"
        )
        device = (
            "cuda"
            if "cuda" in str(self.config.device).lower() and torch.cuda.is_available()
            else "cpu"
        )

        prompts = self.config.structure_prompts or ["object"]
        prompts = [p.strip() for p in prompts if p and p.strip()]
        text_prompt = ". ".join(prompts) if prompts else "object"
        if not text_prompt.endswith("."):
            text_prompt = f"{text_prompt}."

        return TemporalCoherenceConfig(
            meta_info_path=str(meta_info_path),
            text_prompt=text_prompt,
            grounding_config_path=self.config.grounding_dino.config_path,
            grounding_checkpoint_path=self.config.grounding_dino.model_path,
            bert_path=self.config.grounding_dino.bert_path,
            sam2_config_path=self.config.sam.config_path,
            sam2_checkpoint_path=self.config.sam.model_path,
            cotracker_checkpoint_path=cotracker_checkpoint,
            device=device,
            box_threshold=self.config.grounding_dino.box_threshold,
            text_threshold=self.config.grounding_dino.text_threshold,
            grid_size=self.config.tracker.grid_size,
            iou_threshold=0.75,
            enable_visualization=self.config.structure_visualization_enable,
            visualization_output_dir=self.config.structure_visualization_output_dir,
            visualization_max_frames=self.config.structure_visualization_max_frames,
            cotracker_visualization_enable=self.config.cotracker_visualization_enable,
            cotracker_visualization_output_dir=self.config.cotracker_visualization_output_dir,
            cotracker_visualization_fps=self.config.cotracker_visualization_fps,
            cotracker_visualization_mode=self.config.cotracker_visualization_mode,
        )

    def analyze(
        self,
        video_frames: List[np.ndarray],
        text_prompts: Optional[Sequence[str]] = None,
        fps: Optional[float] = None,
        video_path: Optional[str] = None,
    ) -> Dict:
        """
        åˆ†æè§†é¢‘æ—¶åºåˆç†æ€?

        Args:
            video_frames: è§†é¢‘å¸§åºåˆ—ï¼Œæ¯å¸§ä¸ºRGBå›¾åƒ (H, W, 3)
            text_prompts: æ–‡æœ¬æç¤ºåˆ—è¡¨
            fps: è§†é¢‘å¸§ç‡
            video_path: åŸå§‹è§†é¢‘è·¯å¾„ï¼ˆç»“æ„åˆ†æéœ€è¦ï¼‰

        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        if not self._initialized:
            self.initialize()

        if not video_frames:
            raise ValueError("è§†é¢‘å¸§åºåˆ—ä¸ºç©?")

        fps = fps or 30.0

        print("\n" + "=" * 50)
        print("å¼€å§‹åˆ†æè§†é¢‘æ—¶åºåˆç†æ€?...")
        print(f"è§†é¢‘å¸§æ•°: {len(video_frames)}")
        print(f"è§†é¢‘å¸§ç‡: {fps:.2f} fps")
        if text_prompts:
            print(f"æ–‡æœ¬æç¤º: {', '.join(text_prompts)}")
        print("=" * 50)

        # 1. å…‰æµåˆ†æ
        print("\n>>> æ­¥éª¤1: å…‰æµåˆ†æ")
        if hasattr(self.config, "thresholds"):
            self.motion_analyzer.config.motion_discontinuity_threshold = (
                self.config.thresholds.motion_discontinuity_threshold
            )
        motion_score, motion_anomalies = self.motion_analyzer.analyze(video_frames, fps=fps)

        # 2. ç»“æ„åˆ†æ
        print("\n>>> æ­¥éª¤2: å®ä¾‹è¿½è¸ª / ç»“æ„åˆ†æ")
        structure_output = self._analyze_structure(video_path, text_prompts)

        # 3. å…³é”®ç‚¹åˆ†æ?
        print("\n>>> æ­¥éª¤3: å…³é”®ç‚¹åˆ†æ?")
        physiological_score, physiological_anomalies = self.keypoint_analyzer.analyze(
            video_frames, fps=fps, video_path=video_path
        )

        # 4. å¤šæ¨¡æ€èå?
        print("\n>>> æ­¥éª¤4: å¤šæ¨¡æ€èå?")
        fused_anomalies = self.fusion_engine.fuse(
            motion_anomalies,
            structure_output.anomalies,
            physiological_anomalies,
            structure_context={
                "vanish_score": structure_output.vanish_score,
                "emerge_score": structure_output.emerge_score,
                **structure_output.metadata,
            },
        )

        # 5. è®¡ç®—æœ€ç»ˆå¾—åˆ?
        print("\n>>> æ­¥éª¤5: è®¡ç®—æœ€ç»ˆå¾—åˆ?")
        final_motion_score, final_structure_score = self.fusion_engine.compute_final_scores(
            motion_score,
            structure_output.score,
            physiological_score,
            fused_anomalies,
            structure_context={
                "vanish_score": structure_output.vanish_score,
                "emerge_score": structure_output.emerge_score,
                **structure_output.metadata,
            },
        )

        result = {
            "motion_reasonableness_score": float(final_motion_score),
            "structure_stability_score": float(final_structure_score),
            "anomalies": fused_anomalies,
            "sub_scores": {
                "motion_score": float(motion_score),
                "structure_score": float(structure_output.score),
                "physiological_score": float(physiological_score),
            },
            "anomaly_counts": {
                "motion": len(motion_anomalies),
                "structure": len(structure_output.anomalies),
                "physiological": len(physiological_anomalies),
                "fused": len(fused_anomalies),
            },
            "structure_metrics": {
                "coherence_score": float(structure_output.score),
                "vanish_score": float(structure_output.vanish_score),
                "emerge_score": float(structure_output.emerge_score),
                **structure_output.metadata,
            },
        }

        print("\n" + "=" * 50)
        print("åˆ†æå®Œæˆ")
        print("=" * 50)
        print(f"è¿åŠ¨åˆç†æ€§å¾—åˆ?: {final_motion_score:.3f}")
        print(f"ç»“æ„ç¨³å®šæ€§å¾—åˆ?: {final_structure_score:.3f}")
        print(f"æ£€æµ‹åˆ° {len(fused_anomalies)} ä¸ªèåˆå¼‚å¸?")
        print("=" * 50)

        return result

    def _analyze_structure(
        self,
        video_path: Optional[str],
        text_prompts: Optional[Sequence[str]],
    ) -> StructureAnalysisOutput:
        if self.structure_pipeline is None:
            print("è­¦å‘Š: ç»“æ„åˆ†æç®¡çº¿æœªåˆå§‹åŒ–ï¼Œè¿”å›é»˜è®¤ç»“æœã€?")
            return StructureAnalysisOutput(
                score=1.0,
                vanish_score=1.0,
                emerge_score=1.0,
                anomalies=[],
                metadata={},
            )

        if not video_path:
            print("è­¦å‘Š: æœªæä¾›è§†é¢‘è·¯å¾„ï¼Œæ— æ³•æ‰§è¡Œç»“æ„ä¸€è‡´æ€§åˆ†æã€?")
            return StructureAnalysisOutput(
                score=1.0,
                vanish_score=1.0,
                emerge_score=1.0,
                anomalies=[],
                metadata={},
            )

        try:
            result = self.structure_pipeline.evaluate_video(video_path, text_prompts)
            return StructureAnalysisOutput(
                score=float(result.coherence_score),
                vanish_score=float(result.vanish_score),
                emerge_score=float(result.emerge_score),
                anomalies=result.anomalies,
                metadata=result.metadata,
            )
        except Exception as exc:
            print(f"è­¦å‘Š: ç»“æ„åˆ†æå¤±è´¥ï¼Œå°†ä½¿ç”¨é»˜è®¤å¾—åˆ†ã€‚è¯¦æƒ?: {exc}")
            return StructureAnalysisOutput(
                score=1.0,
                vanish_score=1.0,
                emerge_score=1.0,
                anomalies=[],
                metadata={"error": str(exc)},
            )

