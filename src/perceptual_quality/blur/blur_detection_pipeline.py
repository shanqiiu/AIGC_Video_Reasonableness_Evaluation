# -*- coding: utf-8 -*-
"""
è§†é¢‘æ¨¡ç³Šæ£€æµ‹ç®¡é“ï¼ˆMSS + PASï¼?

- ä¸åœ¨ä»£ç ä¸­ä¿®æ”? sys.path æˆ–åˆ‡æ¢å·¥ä½œç›®å½?
- ä¾èµ–è¯·é€šè¿‡å®‰è£…æˆ–ç¯å¢ƒå˜é‡æä¾?
"""

import os
import json
import cv2
import numpy as np
from typing import List, Dict
from pathlib import Path
from tqdm import tqdm
import warnings
warnings.filterwarnings("ignore")

# æ·»åŠ VMBenchè·¯å¾„
# è·å–å½“å‰æ–‡ä»¶çš„ç›®??
current_dir = os.path.dirname(os.path.abspath(__file__))
# AIGC_Video_Reasonableness_Evaluation é¡¹ç›®æ ¹ç›®??
project_root = os.path.abspath(os.path.join(current_dir, '..', '..', '..'))
third_party_dir = os.path.join(project_root, 'third_party')
workspace_root = os.path.abspath(os.path.join(project_root, '..'))
vmb_root = os.path.join(workspace_root, 'VMBench_diy')

# ä¿å­˜åŸå§‹å·¥ä½œç›®å½•
original_cwd = os.getcwd()

from .mss_scorer import MSSScorer
from .pas_scorer import PASScorer
# ä¾èµ–è¯´æ˜ï¼?
# - Grounded-Segment-Anythingã€Co-Trackerã€Q-Align ç­‰ç¬¬ä¸‰æ–¹ä¾èµ–è¯·é€šè¿‡å®‰è£…æˆ–ç¯å¢ƒå˜é‡æä¾?
# - æœ¬æ–‡ä»¶ä¸ç›´æ¥æ“ä½œ sys.pathï¼›å¦‚ä¾èµ–ç¼ºå¤±ï¼Œè¯·åœ¨è°ƒç”¨æ–¹ç¯å¢ƒä¸­è¿›è¡Œå®‰è£…æˆ–é…ç½®


class BlurDetectionPipeline:
    """åŸºäºVMBenchçš„è§†é¢‘æ¨¡ç³Šæ£€æµ‹ç®¡ï¿???"""
    
    def __init__(self, device="cuda:0", model_paths=None):
        """
        åˆå§‹åŒ?
        
        Args:
            device: è®¡ç®—è®¾å¤‡
            model_paths: æ¨¡å‹è·¯å¾„é…ç½®
        """
        self.device = device
        self.model_paths = model_paths or self._get_default_model_paths()
        
        # åˆå§‹åŒ–æ¨¡ï¿???
        self._init_models()
        
        # æ£€æµ‹å‚ï¿???
        self.blur_thresholds = {
            'mss_threshold': 0.025,  # MSSæ£€æµ‹é˜ˆï¿???
            'pas_threshold': 0.1,   # PASæ£€æµ‹é˜ˆï¿???
            'confidence_threshold': 0.7  # ç»¼åˆç½®ä¿¡åº¦é˜ˆï¿???
        }
        
    def _get_default_model_paths(self):
        """è·å–é»˜è®¤æ¨¡å‹è·¯å¾„"""
        # è·å–é¡¹ç›®æ ¹ç›®ï¿???
        current_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.dirname(current_dir)
        
        return {
            'q_align_model': ".cache/q-future/one-align",
            'grounding_dino_config': os.path.join(project_root, "Grounded-Segment-Anything", "GroundingDINO", "groundingdino", "config", "GroundingDINO_SwinB.py"),
            'grounding_dino_checkpoint': ".cache/groundingdino_swinb_cogcoor.pth",
            'bert_path': ".cache/google-bert/bert-base-uncased",
            'sam_checkpoint': ".cache/sam_vit_h_4b8939.pth",
            'cotracker_checkpoint': ".cache/scaled_offline.pth"
        }
    
    def _init_models(self):
        """åˆå§‹åŒ–æ‰€æœ‰éœ€è¦çš„æ¨¡å‹ã€?"""
        print("æ­£åœ¨åˆå§‹åŒ–æ¨¡ç³Šæ£€æµ‹æ¨¡å?...")
        
        try:
            # åˆå§‹åŒ? MSS è¯„åˆ†å™?
            print("  åˆå§‹åŒ? MSS è¯„åˆ†å™?...")
            self.mss_scorer = MSSScorer(
                device=self.device,
                model_paths=self.model_paths,
            )
            
            # åˆå§‹åŒ? PAS è¯„åˆ†å™?
            print("  åˆå§‹åŒ? PAS è¯„åˆ†å™?...")
            self.pas_scorer = PASScorer(
                device=self.device,
                model_paths=self.model_paths,
            )
            # é¢„åŠ è½½ä½“ç§¯è¾ƒå¤§çš„ PAS æ¨¡å‹ï¼ˆéè‡´å‘½å¤±è´¥ï¼?
            try:
                self.pas_scorer.preload_models()
            except Exception:
                pass
            
            print("æ‰€æœ‰æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            print(f"æ¨¡å‹åˆå§‹åŒ–å¤±è´?: {e}")
            raise
    
    def detect_blur_in_video(self, video_path: str, subject_noun: str = "person") -> Dict:
        """
        æ£€æµ‹è§†é¢‘ä¸­çš„æ¨¡ç³Šå¼‚å¸¸ã€?
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            subject_noun: ä¸»ä½“å¯¹è±¡åç§°
            
        Returns:
            æ£€æµ‹ç»“æœå­—å…?
        """
        print(f"å¼€å§‹æ£€æµ‹è§†é¢‘æ¨¡ç³?: {video_path}")
        
        try:
            # 1. ä½¿ç”¨MSSè¯„åˆ†å™¨æ£€æµ‹æ¨¡ï¿???
            mss_results = self._detect_blur_with_mss(video_path)
            
            # 2. ä½¿ç”¨PASè¯„åˆ†å™¨è¾…åŠ©éªŒï¿???
            pas_results = self._detect_blur_with_pas(video_path, subject_noun)
            
            # 3. ç»¼åˆåˆ¤æ–­æ¨¡ç³Šæ£€æµ‹ç»“ï¿???
            blur_results = self._combine_blur_detection(mss_results, pas_results)
            
            # 4. ç”Ÿæˆæ£€æµ‹æŠ¥ï¿???
            detection_report = self._generate_blur_report(video_path, blur_results)
            
            return detection_report
            
        except Exception as e:
            print(f"æ¨¡ç³Šæ£€æµ‹è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return {
                'blur_detected': False,
                'confidence': 0.0,
                'error': str(e),
                'mss_score': 0.0,
                'pas_score': 0.0,
                'blur_frames': []
            }
    
    def _detect_blur_with_mss(self, video_path: str) -> Dict:
        """ä½¿ç”¨ MSS è¯„åˆ†å™¨æ£€æµ‹æ¨¡ç³Šã€?"""
        try:
            # è®¡ç®—è´¨é‡åˆ†æ•°
            mss_output = self.mss_scorer.score(video_path)
            quality_scores = mss_output.get('quality_scores', [])
            
            if not quality_scores or len(quality_scores) == 0:
                raise ValueError("ÖÊÁ¿·ÖÊıÎª¿Õ")
            
            # ¹ÀËãÏà»úÔË¶¯·ù¶È£¨ÓÃÓÚµ÷ÕûãĞÖµ£©
            camera_movement = self._estimate_camera_movement(video_path)
            
            # è‡ªé€‚åº”é˜ˆå€?
            threshold = self._set_threshold(camera_movement)
            
            # æ£€æµ‹æ¨¡ç³Šå¸§
            blur_frames = self._get_artifacts_frames(quality_scores, threshold)
            
            # ¼ÆËãÄ£ºıÖ¸±ê£¨Óësimple_blur_detectorÒ»ÖÂ£©
            blur_metrics = self._calculate_blur_metrics(quality_scores, blur_frames, threshold)
            
            # ¼ÆËã MSS ·ÖÊı
            mss_score = 1 - blur_metrics['blur_ratio'] if blur_metrics['total_frames'] > 0 else 0.0
            
            # è½¬æ¢ blur_frames ä¸ºåˆ—è¡?
            if hasattr(blur_frames, 'tolist'):
                blur_frames_list = blur_frames.tolist()
            else:
                blur_frames_list = list(blur_frames)
            
            return {
                'mss_score': float(mss_score),
                'blur_frames': blur_frames_list,
                'quality_scores': quality_scores,
                'threshold': float(threshold),
                'camera_movement': float(camera_movement),
                'blur_metrics': blur_metrics  # °üº¬ÍêÕûµÄÄ£ºıÖ¸±ê
            }
            
        except Exception as e:
            print(f"MSS æ£€æµ‹å¤±è´?: {e}")
            return {
                'mss_score': 0.0,
                'blur_frames': [],
                'quality_scores': [],
                'threshold': 0.025,
                'camera_movement': 0.0,
                'error': str(e)
            }
    
    def _detect_blur_with_pas(self, video_path: str, subject_noun: str) -> Dict:
        """ä½¿ç”¨ PAS è¯„åˆ†å™¨è¾…åŠ©æ£€æµ‹æ¨¡ç³Šï¼ˆä¸¥æ ¼æŒ‰ç…§å‚è€ƒç‰ˆæœ¬é€»è¾‘ï¼‰ã€?"""
        try:
            out = self.pas_scorer.score(video_path, subject_noun=subject_noun)
            motion_degree = float(out.get('motion_degree', 0.0)) if isinstance(out.get('motion_degree', 0.0), (int, float)) else 0.0
            subject_detected = bool(out.get('subject_detected', False))
            error = out.get('error')
            
            # å¦‚æœæ£€æµ‹å¤±è´¥æˆ–å‡ºé”™ï¼Œè¿”å›é”™è¯¯ç»“æ?
            if not subject_detected or error:
                return {
                    'pas_score': 0.0,
                    'subject_detected': subject_detected,
                    'motion_degree': motion_degree,
                    'error': error
                }
            
            # æŒ‰ç…§å‚è€ƒç‰ˆæœ¬é€»è¾‘ï¼šæ¨¡ç³Šä¼šå¯¼è‡´è¿åŠ¨è·Ÿè¸ªä¸å‡†ç¡®ï¼Œè¿åŠ¨å¹…åº¦å¼‚å¸¸ä½?
            # pas_score = min(1.0, motion_degree * 10)  # å½’ä¸€åŒ–åˆ°0-1
            pas_score = min(1.0, motion_degree * 10)
            
            return {
                'pas_score': float(pas_score),
                'subject_detected': subject_detected,
                'motion_degree': motion_degree,
                'error': None
            }
            
        except Exception as e:
            print(f"PAS æ£€æµ‹å¤±è´?: {e}")
            return {
                'pas_score': 0.0,
                'subject_detected': False,
                'motion_degree': 0.0,
                'error': str(e)
            }
    
    def _estimate_camera_movement(self, video_path: str) -> float:
        """ä¼°ç®—ç›¸æœºè¿åŠ¨å¹…åº¦ã€?"""
        try:
            cap = cv2.VideoCapture(video_path)
            frames = []
            
            # è¯»å–å…³é”®å¸§ï¼ˆå‰? 10 å¸§ï¼‰
            frame_count = 0
            while frame_count < 10:
                ret, frame = cap.read()
                if not ret:
                    break
                frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY))
                frame_count += 1
            cap.release()
            
            if len(frames) < 2:
                return 0.0
            
            # è®¡ç®—å¸§é—´å·®å¼‚
            total_diff = 0.0
            for i in range(1, len(frames)):
                diff = cv2.absdiff(frames[i], frames[i-1])
                total_diff += np.mean(diff)
            
            # å½’ä¸€åŒ–è¿åŠ¨å¹…åº?
            movement = total_diff / (len(frames) - 1) / 255.0
            return min(1.0, movement)
            
        except Exception as e:
            print(f"ç›¸æœºè¿åŠ¨ä¼°ç®—å¤±è´¥: {e}")
            return 0.0
    
    def _calculate_blur_metrics(self, quality_scores: List[float], blur_frames: List[int], threshold: float) -> Dict:
        """¼ÆËãÄ£ºıÖ¸±ê£¨Óësimple_blur_detectorÒ»ÖÂ£©"""
        total_frames = len(quality_scores)
        blur_frame_count = len(blur_frames)
        
        # »ù´¡Ö¸±ê
        blur_ratio = blur_frame_count / total_frames if total_frames > 0 else 0
        avg_quality = np.mean(quality_scores)
        quality_std = np.std(quality_scores)
        
        # ¼ÆËãÖÊÁ¿·ÖÊı±ä»¯
        quality_diffs = np.abs(np.diff(quality_scores))
        max_quality_drop = np.max(quality_diffs) if len(quality_diffs) > 0 else 0
        
        # ¼ÆËãÄ£ºıÑÏÖØ³Ì¶È
        blur_severity = self._determine_blur_severity(blur_ratio, max_quality_drop, threshold, total_frames)
        
        # ¼ÆËã×ÛºÏÖÃĞÅ¶È
        confidence = self._calculate_confidence(blur_ratio, max_quality_drop, avg_quality)
        
        return {
            'total_frames': total_frames,
            'blur_frames': blur_frames,
            'blur_frame_count': blur_frame_count,
            'blur_ratio': float(blur_ratio),
            'avg_quality': float(avg_quality),
            'quality_std': float(quality_std),
            'max_quality_drop': float(max_quality_drop),
            'threshold': float(threshold),
            'blur_severity': blur_severity,
            'confidence': float(confidence),
            'blur_detected': blur_ratio > 0.05 or max_quality_drop > threshold
        }
    
    def _combine_blur_detection(self, mss_results: Dict, pas_results: Dict) -> Dict:
        """ç»¼åˆ MSS ä¸? PAS ç»“æœåˆ¤æ–­æ˜¯å¦æ¨¡ç³Šã€?"""
        mss_score = mss_results.get('mss_score', 0.0)
        pas_score = pas_results.get('pas_score', 0.0)
        blur_frames = mss_results.get('blur_frames', [])
        
        # è®¡ç®—ç»¼åˆç½®ä¿¡åº¦ï¼ˆMSS:0.8, PAS:0.2ï¼?
        confidence = mss_score * 0.8 + pas_score * 0.2
        
        blur_detected = (
            len(blur_frames) > 0 and 
            confidence < self.blur_thresholds['confidence_threshold']
        )
        
        return {
            'blur_detected': blur_detected,
            'confidence': confidence,
            'mss_score': mss_score,
            'pas_score': pas_score,
            'blur_frames': blur_frames,
            'blur_severity': self._calculate_blur_severity(blur_frames, confidence)
        }

    def _set_threshold(self, camera_movement: float) -> float:
        """æ ¹æ®ç›¸æœºè¿åŠ¨è®¾å®šé˜ˆå€¼ï¼ˆä¸¥æ ¼æŒ‰ç…§å‚è€ƒç‰ˆæœ¬é€»è¾‘ï¼‰ã€?"""
        if camera_movement is None:
            return 0.01
        if camera_movement < 0.1:
            return 0.01
        elif 0.1 <= camera_movement < 0.3:
            return 0.015
        elif 0.3 <= camera_movement < 0.5:
            return 0.025
        else:  # camera_movement >= 0.5
            return 0.03

    def _get_artifacts_frames(self, quality_scores: List[float], threshold: float) -> List[int]:
        """æ ¹æ®è´¨é‡åˆ†æ•°ä¸é˜ˆå€¼æå–æ¨¡ç³Šå¸§ç´¢å¼•ï¼ˆä¸¥æ ¼æŒ‰ç…§å‚è€ƒç‰ˆæœ¬é€»è¾‘ï¼‰ã€?"""
        # è®¡ç®—ç›¸é‚»å¸§çš„åˆ†æ•°å·®å¼‚
        score_diffs = np.abs(np.diff(quality_scores))
        
        # æ‰¾å‡ºåˆ†æ•°å·®å¼‚è¶…è¿‡é˜ˆå€¼çš„å¸?
        artifact_indices = np.where(score_diffs > threshold)[0]
        
        # è¿”å›åŒ…å«å½“å‰å¸§å’Œä¸‹ä¸€å¸§çš„ç´¢å¼•ï¼ˆå› ä¸ºæ˜¾è‘—åˆ†æ•°å·®å¼‚å¯èƒ½ç”±ä»»ä¸€å¸§å¼•èµ·ï¼‰
        artifacts_frames = np.unique(np.concatenate([artifact_indices, artifact_indices + 1]))
        
        return artifacts_frames.tolist()
    
    def _calculate_blur_severity(self, blur_frames: List[int], confidence: float) -> str:
        """è®¡ç®—æ¨¡ç³Šä¸¥é‡ç¨‹åº¦ã€?"""
        blur_ratio = len(blur_frames) / 100  # å‡è®¾æ€»å¸§æ•? 100
        if blur_ratio > 0.3 or confidence < 0.3:
            return "ä¸¥é‡æ¨¡ç³Š"
        elif blur_ratio > 0.1 or confidence < 0.5:
            return "ä¸­ç­‰æ¨¡ç³Š"
        elif blur_ratio > 0.05 or confidence < 0.7:
            return "è½»å¾®æ¨¡ç³Š"
        else:
            return "æ— æ¨¡ç³?"
    
    def _generate_blur_report(self, video_path: str, blur_results: Dict) -> Dict:
        """ç”Ÿæˆæ¨¡ç³Šæ£€æµ‹æŠ¥å‘Šã€?"""
        report = {
            'video_path': video_path,
            'video_name': os.path.basename(video_path),
            'detection_timestamp': str(np.datetime64('now')),
            'blur_detected': blur_results['blur_detected'],
            'confidence': blur_results['confidence'],
            'blur_severity': blur_results['blur_severity'],
            'mss_score': blur_results['mss_score'],
            'pas_score': blur_results['pas_score'],
            'blur_frames': blur_results['blur_frames'],
            'total_blur_frames': len(blur_results['blur_frames']),
            'blur_ratio': len(blur_results['blur_frames']) / 100.0,  # å‡è®¾æ€»å¸§æ•? 100
            'recommendations': self._generate_recommendations(blur_results)
        }
        return report
    
    def _generate_recommendations(self, blur_results: Dict) -> List[str]:
        """ç”Ÿæˆæå‡å»ºè®®ã€?"""
        recommendations = []
        
        if blur_results['blur_detected']:
            severity = blur_results['blur_severity']
            if blur_results['blur_severity'] == "ä¸¥é‡æ¨¡ç³Š":
                recommendations.append("å»ºè®®é‡æ–°å½•åˆ¶è§†é¢‘ï¼Œç¡®ä¿ç›¸æœºç¨³å®?")
                recommendations.append("æ£€æŸ¥ç›¸æœºå¯¹ç„¦è®¾ç½?")
            elif blur_results['blur_severity'] == "ä¸­ç­‰æ¨¡ç³Š":
                recommendations.append("å»ºè®®ä½¿ç”¨ä¸‰è„šæ¶æˆ–ç¨³å®šå™?")
                recommendations.append("æé«˜å½•åˆ¶å¸§ç‡")
            else:
                recommendations.append("è½»å¾®æ¨¡ç³Šï¼Œå¯è€ƒè™‘åæœŸå¤„ç†")
        else:
            recommendations.append("è§†é¢‘è´¨é‡è‰¯å¥½ï¼Œæ— éœ€å¤„ç†")
        return recommendations
    
    def batch_detect_blur(self, video_dir: str, output_dir: str = "./blur_detection_results") -> Dict:
        """æ‰¹é‡æ£€æµ‹è§†é¢‘æ¨¡ç³Šã€?"""
        os.makedirs(output_dir, exist_ok=True)
        
        # æ”¶é›†è§†é¢‘æ–‡ä»¶
        video_files = []
        for ext in ['.mp4', '.avi', '.mov', '.mkv']:
            video_files.extend(Path(video_dir).glob(f'*{ext}'))
        
        results = []
        print(f"å¼€å§‹æ‰¹é‡æ£€æµ? {len(video_files)} ä¸ªè§†é¢?...")
        for video_file in tqdm(video_files, desc="æ¨¡ç³Šæ£€æµ‹è¿›åº?"):
            try:
                result = self.detect_blur_in_video(str(video_file))
                results.append(result)
            except Exception as e:
                print(f"å¤„ç†è§†é¢‘ {video_file.name} æ—¶å‡ºé”?: {e}")
                results.append({
                    'video_path': str(video_file),
                    'blur_detected': False,
                    'confidence': 0.0,
                    'error': str(e)
                })
        
        # ä¿å­˜æ‰¹é‡ç»“æœ
        self._save_batch_results(results, output_dir)
        
        return {
            'total_videos': len(video_files),
            'processed_videos': len(results),
            'blur_detected_count': sum(1 for r in results if r.get('blur_detected', False)),
            'results': results
        }
    
    def _make_json_serializable(self, obj):
        """å°? NumPy/PyTorch ç±»å‹è½¬æ¢ä¸ºåŸç”Ÿç±»å‹ã€?"""
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.bool_):
            return bool(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, (list, tuple)):
            return [self._make_json_serializable(item) for item in obj]
        elif isinstance(obj, dict):
            return {key: self._make_json_serializable(value) for key, value in obj.items()}
        elif hasattr(obj, 'item'):
            return obj.item()
        else:
            return obj
    
    def _save_batch_results(self, results: List[Dict], output_dir: str):
        """ä¿å­˜æ‰¹é‡æ£€æµ‹ç»“æœåˆ° JSON/CSV å¹¶ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Šã€?"""
        # JSON
        json_path = os.path.join(output_dir, 'blur_detection_results.json')
        serializable_results = self._make_json_serializable(results)
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(serializable_results, f, indent=2, ensure_ascii=False)
        
        # CSV æ‘˜è¦
        csv_path = os.path.join(output_dir, 'blur_detection_summary.csv')
        import csv
        with open(csv_path, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(['Video', 'Blur_Detected', 'Confidence', 'Severity', 'MSS_Score', 'PAS_Score', 'Blur_Frames'])
            for result in results:
                writer.writerow([
                    os.path.basename(result.get('video_path', '')),
                    result.get('blur_detected', False),
                    f"{result.get('confidence', 0.0):.3f}",
                    result.get('blur_severity', ''),
                    f"{result.get('mss_score', 0.0):.3f}",
                    f"{result.get('pas_score', 0.0):.3f}",
                    len(result.get('blur_frames', []))
                ])
        
        # ç»Ÿè®¡æŠ¥å‘Š
        self._generate_statistics_report(results, output_dir)
        print(f"æ‰¹é‡æ£€æµ‹ç»“æœå·²ä¿å­˜åˆ?: {output_dir}")
    
    def _generate_statistics_report(self, results: List[Dict], output_dir: str):
        """ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Šã€?"""
        total_videos = len(results)
        blur_detected_count = sum(1 for r in results if r.get('blur_detected', False))
        confidence_scores = [r.get('confidence', 0.0) for r in results if 'error' not in r]
        
        report = f"""
# è§†é¢‘æ¨¡ç³Šæ£€æµ‹ç»Ÿè®¡æŠ¥å‘?

## åŸºæœ¬ç»Ÿè®¡
- æ€»è§†é¢‘æ•°é‡?: {total_videos}
- æ£€æµ‹åˆ°æ¨¡ç³Šçš„è§†é¢?: {blur_detected_count}
- æ¨¡ç³Šæ£€æµ‹ç‡: {blur_detected_count/total_videos*100:.1f}%

## ç½®ä¿¡åº¦ç»Ÿè®?
- å¹³å‡ç½®ä¿¡åº?: {np.mean(confidence_scores):.3f}
- æœ€ä½ç½®ä¿¡åº¦: {np.min(confidence_scores):.3f}
- æœ€é«˜ç½®ä¿¡åº¦: {np.max(confidence_scores):.3f}
- ç½®ä¿¡åº¦æ ‡å‡†å·®: {np.std(confidence_scores):.3f}

## æ¨¡ç³Šä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ
"""
        
        severity_counts = {}
        for result in results:
            if result.get('blur_detected', False):
                severity = result.get('blur_severity', 'æœªçŸ¥')
                severity_counts[severity] = severity_counts.get(severity, 0) + 1
        for severity, count in severity_counts.items():
            report += f"- {severity}: {count} ä¸ªè§†é¢‘\n"
        
        report_path = os.path.join(output_dir, 'statistics_report.txt')
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)
    