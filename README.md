# AI生成视频合理性评估最终方案

> **版本**：1.0  
> **日期**：2025年10月30日  
> **目标**：仅基于一段AI生成视频，自动评估其合理性，输出结构化报告，并提供动态程度等辅助元信息。

---

## 一、总体架构

系统由 **四大核心评估模块 + 一个辅助分析模块** 组成：

```
[输入视频]
     ↓
┌───────────────────────┐
│ 辅助模块：动态程度分析 │ ← 输出动态度分数（不计入总分）
└───────────────────────┘
     ↓
┌───────────────────────┐
│ 模块1：时序合理性分析 │ ← 光流、实例分割、关键点追踪
└───────────────────────┘
     ↓
┌───────────────────────┐
│ 模块2：场景真实感评估 │ ← 前景-背景解耦、物体交互分析
└───────────────────────┘
     ↓
┌───────────────────────┐
│ 模块3：AI感知质量评估 │ ← 伪影检测（闪烁、模糊、色彩漂移等）
└───────────────────────┘
     ↓
┌───────────────────────┐
│ 模块4：VLM常识推理     │ ← 多模态大模型零样本判断
└───────────────────────┘
     ↓
┌───────────────────────┐
│ 融合评估引擎           │ ← 仅融合模块1–4，生成合理性评分与报告
└───────────────────────┘
     ↓
[合理性报告 + 动态度元信息]
```

---

## 二、模块详细说明

### 2.1 辅助模块：动态程度分析（Motion Intensity Analyzer）
- **目标**：量化视频整体运动强度，区分静态/动态场景
- **方法**：
  - 计算平均光流幅值 或 帧间 LPIPS 变化率
  - 归一化为 `[0.0, 1.0]` 动态度分数
  - 按阈值划分场景类型：`"static"`（<0.2）、`"moderate"`（0.2–0.6）、`"dynamic"`（>0.6）
- **输出**：
  - `motion_intensity: float`
  - `scene_type: string`
- **用途**：
  - 调整其他模块敏感度（如静态场景下提高闪烁检测阈值）
  - 作为报告元信息，辅助人工判断
- **注意**：**不参与总合理性评分**

---

### 2.2 模块1：时序合理性分析
- **目标**：检测运动与结构的时序连贯性
- **方法**：
  - 光流分析（RAFT）评估全局运动平滑度
  - Grounding DINO + SAM + DeAOT 实现关键词引导的实例分割与跨帧追踪
  - MediaPipe 提取关键点，分析眨眼、嘴型等动作自然性
- **输出**：运动合理性得分、结构稳定性得分、异常实例列表

### 2.3 模块2：场景真实感评估
- **目标**：评估背景刚性与物体交互真实性
- **方法**：
  - 前景-背景分割（MODNet/RVM）
  - 背景刚性区域（如“黑板”）的局部光流与前景运动相关性分析
  - 物体间交互分析（如“露珠”与“荷叶”）：边界嵌合度 + 相对运动
- **输出**：场景刚性违反标志、交互失真标志

### 2.4 模块3：AI感知质量评估（伪影检测）
- **目标**：识别影响视觉可信度的低层伪影
- **方法**（轻量、无监督）：
  - **闪烁检测**：Laplacian方差或局部标准差的时序突变
  - **异常模糊**：清晰度显著下降且无对应运动
  - **色彩漂移**：HSV直方图EMD距离突增
  - **纹理崩坏**：高频能量异常爆发
- **输出**：伪影类型、时间戳、视觉质量子分

### 2.5 模块4：VLM常识推理
- **目标**：高层语义合理性判断
- **方法**：
  - 使用 Qwen-VL、LLaVA 等多模态大模型
  - 结构化提示聚焦可见内容（如“张嘴时口腔是否可见？”）
- **输出**：常识合理性判断（含维度、原因、时间戳）

---

## 三、融合评估引擎

### 3.1 评分体系
仅融合四大核心模块，**动态程度不参与**：

```
总合理性得分 = 
  w₁ × 运动合理性 +
  w₂ × 结构稳定性 +
  w₃ × 场景真实感 +
  w₄ × 视觉质量（伪影）+
  w₅ × VLM常识合理性
```
- 默认权重均等（各 0.2），支持按场景配置

### 3.2 异常分级
- **Critical**：违反基本物理/生物规律（如舌头消失）
- **Moderate**：场景扭曲、交互失真、明显闪烁
- **Minor**：轻微模糊、色彩漂移、纹理瑕疵

### 3.3 输出报告（JSON）
```json
{
  "overall_score": 0.72,
  "grade": "B",
  "motion_intensity": 0.08,
  "scene_type": "static",
  "issues": [
    {
      "severity": "Critical",
      "type": "Structural Inconsistency",
      "description": "第3.2秒张嘴状态下口腔内部不可见",
      "timestamp": "3.2s"
    },
    {
      "severity": "Moderate",
      "type": "Temporal Flickering",
      "description": "背景纹理在2.1–2.4秒间闪烁",
      "timestamp": "2.1–2.4s"
    }
  ]
}
```

---

## 四、核心约束与优势

- ✅ **仅依赖视频像素**，无需生理信号、外部参考或生成模型信息  
- ✅ **支持关键词引导**（如 `"tongue"`, `"blackboard"`）  
- ✅ **动态程度独立输出**，可作上下文参考，不影响主评分  
- ✅ **计算可控**：伪影检测轻量，VLM仅用于关键片段  
- ✅ **全面覆盖**：从低层伪影到高层逻辑，形成合理性闭环  

> **最终目标**：确保AI生成视频“**结构稳、运动顺、交互真、无闪烁、合常识**”，并提供场景动态上下文以增强系统适应性。
